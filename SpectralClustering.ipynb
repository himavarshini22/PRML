{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the unlabelled data (Data A) into an adjacency matrix using D_{i,j} = exp(-\\gamma * ||x_i - x_j||). Convert the adjacency matrix into a Laplacian and find the lowest n eigen-vectors and use that to create feature matrix of shape num_samples-by-n. Use k-means clustering to cluster the resulting data.  \n",
    "\n",
    "Now plot the following scatterplots of the data with clusterlabels as colors.\n",
    "\n",
    "\n",
    "1. The results of k-means clustering on the raw data with k=3.\n",
    "2. The results of spectral clustering with k-means on the eigen features with gamma, n, k set to 10,3 and 3.\n",
    "3. The results of spectral clustering with k-means on the eigen features with gamma, n, k set to 10,10 and 3.\n",
    "4. The results of spectral clustering with k-means on the eigen features with gamma, n, k set to 1, 3 and 3.\n",
    "5. The results of spectral clustering with k-means on the eigen features with gamma, n, k set to 1, 10 and 3.\n",
    "\n",
    "\n",
    "Comment on the nature of the results in the text cell below.\n",
    "\n",
    "You are only allowed to use the pratical eigen vector finder given as defined above here. This is meant to simulate real eigen solvers which are iterative and approximate in nature. You can use the import of KMeans from sklearn to begin with, but the final submission should be based on your own implementation of kMeans or there will be a penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans # This will be commented out during evaluation. Write your own k-means code.\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import load_digits\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def practical_eigen_symmetric(L):\n",
    "    # Returns the eigen values and eigen vectors of a symmetric matrix L. eigen values are sorted in ascending order, and eig_vecs[:,i] corresponds to the ith eigen vector\n",
    "    eig_vals, eig_vecs = np.linalg.eigh(L)\n",
    "    eig_vecs = np.array(eig_vecs, dtype=np.float16)\n",
    "    eig_vecs = np.array(eig_vecs, dtype=np.float32)\n",
    "    return eig_vals, eig_vecs\n",
    "\n",
    "def custom_kmeans(X, n_clusters, n_init=10, max_iter=300, tol=1e-4, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    best_inertia = np.inf\n",
    "    best_centroids = None\n",
    "    best_labels = None\n",
    "\n",
    "    for _ in range(n_init):\n",
    "        # Randomly initialize the centroids\n",
    "        centroids = X[np.random.choice(X.shape[0], n_clusters, replace=False)]\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # Assign clusters based on closest centroid\n",
    "            distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Calculate new centroids\n",
    "            new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(n_clusters)])\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.all(np.linalg.norm(new_centroids - centroids, axis=1) < tol):\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "\n",
    "        # Calculate inertia\n",
    "        inertia = np.sum([np.sum((X[labels == i] - centroids[i]) ** 2) for i in range(n_clusters)])\n",
    "\n",
    "        if inertia < best_inertia:\n",
    "            best_inertia = inertia\n",
    "            best_centroids = centroids\n",
    "            best_labels = labels\n",
    "\n",
    "    return best_labels, best_centroids\n",
    "\n",
    "\n",
    "def Laplacian(dataA, gamma, n, k):\n",
    "    x = len(dataA)\n",
    "    d = np.zeros((x, x))\n",
    "    D = np.zeros((x, x))\n",
    "\n",
    "    for i in range(x):\n",
    "        for j in range(x):\n",
    "            d[i][j] = np.exp(-gamma * (np.sqrt(sum(pow(element, 2) for element in (dataA[i] - dataA[j])))))\n",
    "\n",
    "    for i in range(x):\n",
    "        D[i][i] = np.sum(d[i])\n",
    "\n",
    "    L = D - d\n",
    "    eig_vals, eig_vecs = practical_eigen_symmetric(L)\n",
    "    U = eig_vecs[:, :n]\n",
    "\n",
    "    labels, C = custom_kmeans(U, n_clusters=k, random_state=0)\n",
    "\n",
    "    return labels\n",
    "\n",
    "dataA = np.load(\"Data/Dataset_A.npy\")\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20,5))\n",
    "ax = axs[0]\n",
    "labels, C = custom_kmeans(dataA, n_clusters=3, random_state=0)\n",
    "ax.scatter(dataA[:, 0], dataA[:, 1], c=labels, cmap='viridis')\n",
    "ax.set_title(f'k mean on raw data,k={3}')\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "\n",
    "labels = Laplacian(dataA,10, 3, 3)\n",
    "axs[1].scatter(dataA[:, 0], dataA[:, 1], c=labels, cmap='viridis')\n",
    "axs[1].set_title(f'Spectral Clustering\\nγ={10}, n={3}, k={3}')\n",
    "axs[1].set_xlabel('Feature 1')\n",
    "axs[1].set_ylabel('Feature 2')\n",
    "\n",
    "labels=Laplacian(dataA, 10, 10, 3)\n",
    "axs[2].scatter(dataA[:, 0], dataA[:, 1], c=labels, cmap='viridis')\n",
    "axs[2].set_title(f'Spectral Clustering\\nγ={10}, n={10}, k={3}')\n",
    "axs[2].set_xlabel('Feature 1')\n",
    "axs[2].set_ylabel('Feature 2')\n",
    "\n",
    "labels=Laplacian(dataA,1, 3, 3)\n",
    "axs[3].scatter(dataA[:, 0], dataA[:, 1], c=labels, cmap='viridis')\n",
    "axs[3].set_title(f'Spectral Clustering\\nγ={1}, n={3}, k={3}')\n",
    "axs[3].set_xlabel('Feature 1')\n",
    "axs[3].set_ylabel('Feature 2')\n",
    "\n",
    "labels=Laplacian(dataA,1, 10, 3)\n",
    "axs[4].scatter(dataA[:, 0], dataA[:, 1], c=labels, cmap='viridis')\n",
    "axs[4].set_title(f'Spectral Clustering\\nγ={1}, n={10}, k={3}')\n",
    "axs[4].set_xlabel('Feature 1')\n",
    "axs[4].set_ylabel('Feature 2')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
